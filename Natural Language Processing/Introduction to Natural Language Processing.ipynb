{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is difficult for computer to understand unstructured language. Humans language lacks structure. A more structured language is maths where we define relationships between variables and it is easy for the computer to understand and process structured language. Another example of structured language is scripting and programming languages. The lack of structure in the languages in which humans communicate makes it difficult for computers to understand our language.\n",
    "\n",
    "Structured langauge are easy to parse and understand for computers since they are defined by a strict set of rules or grammar. There are standard forms of expressing such grammars and algorithms that can parse properly formed statements to understand exactly what is meant. When a statement doesn't match a prescribed grammar, a typical computer does not try to guess the meaning and it simply gives up. Such violations of grammar is called syntax error.\n",
    "\n",
    "The language which we humans use also has defined grammatical structure and indeed in some situations we also use simple structured sentences. But for the most part, human discourse is complex and unstructured. Despite that, humans are able to understand each other nicely and even ambiquities are welcome to us for a certain extent. For computers to make sense of unstructured text, they process words and phrases by identifying keywords, parts of speech, named entities, dates and quantities. Using all of this, computers can parse sentences at least once that are more structured. This can help extract relevant parts of statements, questions or instructions. At a high level, computers can analyze documents to find frequent and rare words, assess the overall tone or sentiment being expressed and even cluster or group several documents together. So as a result computers can do a lot more on the document even if they do not understand it like us.\n",
    "\n",
    "Context plays a very important role for the computer to analyze the text. For example - Sentence 1 = The sofa didn't fit through the door because it was too narrow. Here it is being referred to as the door. Sentence 2 = The sofa didn't fit through the door because it was too wide. Here in sentence 2 , it is being referred to as the sofa. To understand the proper meaning or semantics of the sentence, we applied our knowledge of the physical world that wide things don't fit through narrow things since we may have experienced or seen a similar situation before. So context is indespensible here in order to correctly understand what is being said."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Pipeline\n",
    "\n",
    "A common NLP Pipeline consists of 3 stages namely Text Processing, Feature Extraction and Modeling. Each stage transforms text in some way and processes text so that it can be used by next stage.\n",
    "\n",
    "# Text Processing\n",
    "\n",
    "Even thought the internet is the fastest growing source of information, we may get the information from various sources such as word document, pdf document, a book scanned or even an audio. The main goal of text processing step is to extract plain text that is free from any source specific markers or constructs that are not relevant to the task. We can eliminate the comma, semicolon and other punctuation marks. Even the very common words such as a, an, the are used to provide structure to the sentence, but they can be eliminated since they do not contribute much to the meaning of the sentence and eliminating them also reduces the complexity of the sentence.\n",
    "\n",
    "# Feature Extraction\n",
    "\n",
    "Text data is represented on computer using encoding such as ASCII code which maps every input to a number. Computers store and transmit these values as binary(0's and 1's). Unfortunately computers do not have any standard representation for words even though they are internally sequence of ASCII or Unicode values. The ASCII representation fails to capture the internal meaning or relationship between words. The technique we are going to use will depend on the end model which we are aiming at to be made.\n",
    "\n",
    "# Modeling\n",
    "\n",
    "Final stage. Involves designing a model, usually a statistical or machine learning model, fitting it's parameters to training data using an optimization procedure and then using it to make predictions about unseen data. Good thing about working with numerical features is that it allows us to utilize pretty much any machine learning model be it support vector machine, decision trees , neural networks or any custom model of choice. We can even combine multiple models in order to get better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
